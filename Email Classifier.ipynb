{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27c0293b-5fae-4d6b-94e0-fe5870a4df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62e648e8-91a4-48e7-a116-c0631c0133d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "# 1.Load Dataset\n",
    "dataset = load_dataset(\"SetFit/enron_spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5774329d-1e67-4310-86bb-8053b9efb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand to contextual labels\n",
    "def map_label(example):\n",
    "    if example[\"label\"] == 1:\n",
    "        example[\"category\"] = \"Promotional\"\n",
    "    else:\n",
    "        text = example[\"text\"].lower()\n",
    "        if \"meeting\" in text or \"project\" in text or \"deadline\" in text:\n",
    "            example[\"category\"] = \"Work-related\"\n",
    "        elif \"urgent\" in text or \"immediately\" in text:\n",
    "            example[\"category\"] = \"Urgent\"\n",
    "        else:\n",
    "            example[\"category\"] = \"Informational\"\n",
    "    return example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b22ba01e-b04e-4e1a-9876-f3ce7d2ed04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(map_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff2d8118-2b1b-448b-ae5d-9faf0d168848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a smaller subset for speed\n",
    "train_ds = dataset[\"train\"].shuffle(seed=42).select(range(400))\n",
    "test_ds = dataset[\"test\"].shuffle(seed=42).select(range(150))\n",
    "\n",
    "# Encode label categories\n",
    "unique_labels = list(set(train_ds[\"category\"]))\n",
    "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "def encode_labels(example):\n",
    "    example[\"label\"] = label2id[example[\"category\"]]\n",
    "    return example\n",
    "\n",
    "train_ds = train_ds.map(encode_labels)\n",
    "test_ds = test_ds.map(encode_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7451cf1-9837-4e03-9bcb-e6d35223d44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69523c749211495ea3319a3580ec07a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2 Tokenization\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_enc = train_ds.map(tokenize, batched=True)\n",
    "test_enc = test_ds.map(tokenize, batched=True)\n",
    "train_enc.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_enc.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92ee9e82-119a-4d64-a9d6-88b9ba740015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 3Ô∏è Model Setup\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=len(unique_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7adf4a37-3e66-4633-96e8-906304b47134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Ô∏è Training Setup\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"weighted\"\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_enc,\n",
    "    eval_dataset=test_enc,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f62cc89-a2f5-4013-8a2c-78d3ea07909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 08:13, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.6030052947998047, metrics={'train_runtime': 500.52, 'train_samples_per_second': 1.598, 'train_steps_per_second': 0.2, 'total_flos': 26494424678400.0, 'train_loss': 0.6030052947998047, 'epoch': 2.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 5 Train Model\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaf7c549-8caa-4ff7-a142-c4fbfeb1306d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Evaluation Results: {'eval_loss': 0.33723804354667664, 'eval_accuracy': 0.8866666666666667, 'eval_f1': 0.8486454910551295, 'eval_precision': 0.816031746031746, 'eval_recall': 0.8866666666666667, 'eval_runtime': 21.0302, 'eval_samples_per_second': 7.133, 'eval_steps_per_second': 0.903, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# 6Ô∏è Evaluate Model\n",
    "\n",
    "results = trainer.evaluate()\n",
    "print(\"\\nüìä Evaluation Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff32c5f2-71b6-47a9-9a94-14136fcaab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìß Email: We have an urgent client meeting tomorrow. Please prepare the report.\n",
      "Predicted Context: Informational\n"
     ]
    }
   ],
   "source": [
    "# 8Ô∏è Custom Email Prediction\n",
    "\n",
    "def predict_email_context(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    pred = torch.argmax(outputs.logits).item()\n",
    "    return id2label[pred]\n",
    "\n",
    "sample_email = \"We have an urgent client meeting tomorrow. Please prepare the report.\"\n",
    "print(f\"\\nüìß Email: {sample_email}\")\n",
    "print(f\"Predicted Context: {predict_email_context(sample_email)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea78a3de-9bb9-4b8d-8447-12f9f3e3df92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('context_email_classifier\\\\tokenizer_config.json',\n",
       " 'context_email_classifier\\\\special_tokens_map.json',\n",
       " 'context_email_classifier\\\\vocab.txt',\n",
       " 'context_email_classifier\\\\added_tokens.json',\n",
       " 'context_email_classifier\\\\tokenizer.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7Ô∏è Save Model\n",
    "\n",
    "model.save_pretrained(\"context_email_classifier\")\n",
    "tokenizer.save_pretrained(\"context_email_classifier\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
